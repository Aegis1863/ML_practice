{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¤šæ™ºèƒ½ä½“åŸºç¡€\n",
    "\n",
    "å¤šæ™ºèƒ½ä½“æ¡ä»¶ä¸‹ï¼Œç¯å¢ƒæ˜¯éç¨³æ€çš„ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½åœ¨æ”¹å˜ç¯å¢ƒï¼Œæ‰€ä»¥è½¬ç§»æ¦‚ç‡ä¹Ÿå¯èƒ½ç»å¸¸å˜åŒ–ã€‚\n",
    "\n",
    "* å®Œå…¨ä¸­å¿ƒåŒ–ï¼ˆfully centralizedï¼‰æ–¹æ³•ï¼šå°†å¤šä¸ªæ™ºèƒ½ä½“è¿›è¡Œå†³ç­–å½“ä½œä¸€ä¸ªè¶…çº§æ™ºèƒ½ä½“åœ¨è¿›è¡Œå†³ç­–ï¼Œå³æŠŠæ‰€æœ‰æ™ºèƒ½ä½“çš„çŠ¶æ€èšåˆåœ¨ä¸€èµ·å½“ä½œä¸€ä¸ªå…¨å±€çš„è¶…çº§çŠ¶æ€ï¼ŒæŠŠæ‰€æœ‰æ™ºèƒ½ä½“çš„åŠ¨ä½œè¿èµ·æ¥ä½œä¸ºä¸€ä¸ªè”åˆåŠ¨ä½œï¼Œå¥½å¤„æ˜¯ç¯å¢ƒä»ç„¶æ˜¯ç¨³æ€çš„ï¼Œæ”¶æ•›æ€§æœ‰ä¿è¯ï¼Œä½†æ˜¯çŠ¶æ€ç©ºé—´æˆ–è€…åŠ¨ä½œç©ºé—´å¤ªå¤§å¯èƒ½å¯¼è‡´ç»´åº¦çˆ†ç‚¸ã€‚\n",
    "* å®Œå…¨å»ä¸­å¿ƒåŒ–ï¼ˆfully decentralizedï¼‰ï¼šå‡è®¾æ¯ä¸ªæ™ºèƒ½ä½“éƒ½åœ¨è‡ªèº«çš„ç¯å¢ƒä¸­ç‹¬ç«‹åœ°è¿›è¡Œå­¦ä¹ ï¼Œä¸è€ƒè™‘å…¶ä»–æ™ºèƒ½ä½“çš„æ”¹å˜ã€‚æ¯ä¸ªæ™ºèƒ½ä½“å•ç‹¬é‡‡ç”¨ä¸€ä¸ªå¼ºåŒ–ç®—æ³•è®­ç»ƒï¼Œä½†æ˜¯ç¯å¢ƒéç¨³æ€ï¼Œæ”¶æ•›æ€§ä¸èƒ½ä¿è¯ã€‚\n",
    "\n",
    "ä»ç„¶å®šä¹‰PPOæˆ–è€…å…¶ä»–ç®—æ³•ï¼Œåœ¨è®­ç»ƒæ—¶ï¼Œå»ºç«‹å¤šä¸ªæ™ºèƒ½ä½“ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“å•ç‹¬ç”¨ä¸€ä¸ªtransitionè¡¨å³å¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä¸­å¿ƒåŒ–è®­ç»ƒå»ä¸­å¿ƒåŒ–æ‰§è¡Œ(CTDE)\n",
    "\n",
    "æ˜¯æŒ‡åœ¨è®­ç»ƒçš„æ—¶å€™ä½¿ç”¨ä¸€äº›å•ä¸ªæ™ºèƒ½ä½“çœ‹ä¸åˆ°çš„å…¨å±€ä¿¡æ¯è€Œä»¥è¾¾åˆ°æ›´å¥½çš„è®­ç»ƒæ•ˆæœï¼Œè€Œåœ¨æ‰§è¡Œæ—¶ä¸ä½¿ç”¨è¿™äº›ä¿¡æ¯ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“å®Œå…¨æ ¹æ®è‡ªå·±çš„ç­–ç•¥ç›´æ¥åŠ¨ä½œä»¥è¾¾åˆ°å»ä¸­å¿ƒåŒ–æ‰§è¡Œçš„æ•ˆæœã€‚ä¸­å¿ƒåŒ–è®­ç»ƒå»ä¸­å¿ƒåŒ–æ‰§è¡Œçš„ç®—æ³•èƒ½å¤Ÿåœ¨è®­ç»ƒæ—¶æœ‰æ•ˆåœ°åˆ©ç”¨å…¨å±€ä¿¡æ¯ä»¥è¾¾åˆ°æ›´å¥½ä¸”æ›´ç¨³å®šçš„è®­ç»ƒæ•ˆæœï¼ŒåŒæ—¶åœ¨è¿›è¡Œç­–ç•¥æ¨¡å‹æ¨æ–­æ—¶å¯ä»¥ä»…åˆ©ç”¨å±€éƒ¨ä¿¡æ¯ï¼Œä½¿å¾—ç®—æ³•å…·æœ‰ä¸€å®šçš„æ‰©å±•æ€§ã€‚CTDE å¯ä»¥ç±»æ¯”æˆä¸€ä¸ªè¶³çƒé˜Ÿçš„è®­ç»ƒå’Œæ¯”èµ›è¿‡ç¨‹ï¼šåœ¨è®­ç»ƒæ—¶ï¼Œ11 ä¸ªçƒå‘˜å¯ä»¥ç›´æ¥è·å¾—æ•™ç»ƒçš„æŒ‡å¯¼ä»è€Œå®Œæˆçƒé˜Ÿçš„æ•´ä½“é…åˆï¼Œè€Œæ•™ç»ƒæœ¬èº«æŒæ¡ç€æ¯”èµ›å…¨å±€ä¿¡æ¯ï¼Œæ•™ç»ƒçš„æŒ‡å¯¼ä¹Ÿæ˜¯ä»æ•´æ”¯é˜Ÿã€æ•´åœºæ¯”èµ›çš„è§’åº¦è¿›è¡Œçš„ï¼›è€Œè®­ç»ƒå¥½çš„ 11 ä¸ªçƒå‘˜åœ¨ä¸Šåœºæ¯”èµ›æ—¶ï¼Œåˆ™æ ¹æ®åœºä¸Šçš„å®æ—¶æƒ…å†µç›´æ¥åšå‡ºå†³ç­–ï¼Œä¸å†æœ‰æ•™ç»ƒçš„æŒ‡å¯¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â—æ³¨æ„\n",
    "\n",
    "æœªé…ç½®ç¯å¢ƒï¼Œæœ¬èŠ‚ä»£ç æ— æ³•è¿è¡Œï¼Œ[å‚è€ƒ](https://hrl.boyuai.com/chapter/3/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6)ï¼Œå› æ‰§è¡Œå®‰è£…ç¯å¢ƒæŒ‡ä»¤å¯¼è‡´condaæŸåä¸€æ¬¡ï¼Œå› æ­¤ä¸å»ºè®®è¿è¡Œã€‚\n",
    "\n",
    "æœ¬ç¬”è®°å¯¹ä»£ç ç»†èŠ‚è¿›è¡Œäº†é¢å¤–æ ‡æ³¨ä¾¿äºç†è§£æ€æƒ³ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import rl_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gumbel-softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_from_logits(logits, eps=0.01):\n",
    "    ''' ç”Ÿæˆæœ€ä¼˜åŠ¨ä½œçš„ç‹¬çƒ­ï¼ˆone-hotï¼‰å½¢å¼ '''\n",
    "    argmax_acs = (logits == logits.max(1, keepdim=True)[0]).float()\n",
    "    # ç”ŸæˆéšæœºåŠ¨ä½œ,è½¬æ¢æˆç‹¬çƒ­å½¢å¼\n",
    "    rand_acs = torch.autograd.Variable(torch.eye(logits.shape[1])[[\n",
    "        np.random.choice(range(logits.shape[1]), size=logits.shape[0])\n",
    "    ]],\n",
    "                                       requires_grad=False).to(logits.device)\n",
    "    # é€šè¿‡epsilon-è´ªå©ªç®—æ³•æ¥é€‰æ‹©ç”¨å“ªä¸ªåŠ¨ä½œï¼Œræ˜¯\n",
    "    return torch.stack([\n",
    "        argmax_acs[i] if r > eps else rand_acs[i]\n",
    "        for i, r in enumerate(torch.rand(logits.shape[0]))\n",
    "    ])\n",
    "\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-20, tens_type=torch.FloatTensor):\n",
    "    \"\"\"ä»Gumbel(0,1)åˆ†å¸ƒä¸­é‡‡æ ·\"\"\"\n",
    "    U = torch.autograd.Variable(tens_type(*shape).uniform_(),\n",
    "                                requires_grad=False)\n",
    "    return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    \"\"\" ä»Gumbel-Softmaxåˆ†å¸ƒä¸­é‡‡æ ·ï¼ŒåŠ ä¸Šä»sample_gumbelç”Ÿæˆçš„å™ªå£°\"\"\"\n",
    "    y = logits + sample_gumbel(logits.shape, tens_type=type(logits.data)).to(\n",
    "        logits.device)\n",
    "    return F.softmax(y / temperature, dim=1)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, temperature=1.0):\n",
    "    \"\"\"ä»Gumbel-Softmaxåˆ†å¸ƒä¸­é‡‡æ ·,å¹¶è¿›è¡Œç¦»æ•£åŒ–\"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    y_hard = onehot_from_logits(y)\n",
    "    y = (y_hard.to(logits.device) - y).detach() + y  # * å¼ï¼ˆ1ï¼‰\n",
    "    # * å‡ä¸€ä¸ªyå†åŠ ä¸€ä¸ªyï¼Œä»ç„¶æ˜¯onehot_yï¼Œä¹Ÿå°±æ˜¯ç¦»æ•£çš„action\n",
    "    # è¿”å›ä¸€ä¸ªy_hardçš„ç‹¬çƒ­é‡,ä½†æ˜¯å®ƒçš„æ¢¯åº¦æ˜¯y,æˆ‘ä»¬æ—¢èƒ½å¤Ÿå¾—åˆ°ä¸€ä¸ªä¸ç¯å¢ƒäº¤äº’çš„ç¦»æ•£åŠ¨ä½œ,åˆå¯ä»¥\n",
    "    # æ­£ç¡®åœ°åä¼ æ¢¯åº¦\n",
    "    # * æˆ‘çš„ç†è§£æ˜¯ï¼Œå¯¹äºæœ€åreturnçš„yæ¥è¯´ï¼Œæ˜¯ç¦»æ•£çš„åŠ¨ä½œï¼ˆç‹¬çƒ­çš„ï¼‰ï¼Œä½†æ˜¯æ±‚æ¢¯åº¦æ—¶ï¼Œ\n",
    "    # * åœ¨å¼ï¼ˆ1ï¼‰ä¸­ï¼Œç”±äºå‰é¢detachäº†ï¼Œæ²¡æœ‰æ¢¯åº¦ï¼Œå› æ­¤åªå¯¹åä¸€ä¸ªyæ±‚æ¢¯åº¦ï¼Œ\n",
    "    # * è¿™ä¸ªyæ˜¯æ¥è‡ªä¸Šä¸€ä¸ªå‡½æ•°gumbel_softmax_sampleå¾—åˆ°çš„yï¼Œè¿™æ ·å°±å¯ä»¥åå‘ä¼ æ’­äº†\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerFC(torch.nn.Module):\n",
    "    def __init__(self, num_in, num_out, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(num_in, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim, num_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "class DDPG:\n",
    "    ''' DDPGç®—æ³•, å‚æ•°æ›´æ–°å†™åœ¨MADDPGä¸­ '''\n",
    "    def __init__(self, state_dim, action_dim, critic_input_dim, hidden_dim,\n",
    "                 actor_lr, critic_lr, device):\n",
    "        self.actor = TwoLayerFC(state_dim, action_dim, hidden_dim).to(device)\n",
    "        self.target_actor = TwoLayerFC(state_dim, action_dim, hidden_dim).to(device)\n",
    "        self.critic = TwoLayerFC(critic_input_dim, 1, hidden_dim).to(device)\n",
    "        self.target_critic = TwoLayerFC(critic_input_dim, 1, hidden_dim).to(device)\n",
    "        self.target_critic.load_state_dict(self.critic.state_dict())\n",
    "        self.target_actor.load_state_dict(self.actor.state_dict())\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=critic_lr)\n",
    "\n",
    "    def take_action(self, state, explore=False):\n",
    "        action = self.actor(state)\n",
    "        if explore:  # *æ¢ç´¢æ—¶ï¼Œéœ€è¦è®­ç»ƒæ¨¡å‹ï¼Œgumbel_softmaxå¯ä»¥åå‘ä¼ æ’­\n",
    "            action = gumbel_softmax(action)\n",
    "        else:  # * åº”ç”¨æ—¶ï¼Œä¸éœ€è¦è®­ç»ƒæ¨¡å‹ï¼Œonehot_from_logitsç›´æ¥æŠŠè¿ç»­åŠ¨ä½œç¦»æ•£ï¼Œ\n",
    "               # * æ— æ³•åå‘ä¼ æ’­ï¼Œä½†æ˜¯è¿”å›çš„ç»“æœåªæ¯”gumbel_softmaxå°‘ä¸€ä¸ªå™ªå£°ï¼Œå·®åˆ«ä¸å¤§\n",
    "            action = onehot_from_logits(action)\n",
    "        return action.detach().cpu().numpy()[0]\n",
    "\n",
    "    def soft_update(self, net, target_net, tau):\n",
    "        for param_target, param in zip(target_net.parameters(),\n",
    "                                       net.parameters()):\n",
    "            param_target.data.copy_(param_target.data * (1.0 - tau) +\n",
    "                                    param.data * tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MADDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MADDPG:\n",
    "    def __init__(self, env, device, actor_lr, critic_lr, hidden_dim,\n",
    "                 state_dims, action_dims, critic_input_dim, gamma, tau):\n",
    "        self.agents = []\n",
    "        for i in range(len(env.agents)):\n",
    "            self.agents.append(\n",
    "                DDPG(state_dims[i], action_dims[i], critic_input_dim,\n",
    "                     hidden_dim, actor_lr, critic_lr, device))\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.critic_criterion = torch.nn.MSELoss()\n",
    "        self.device = device\n",
    "\n",
    "    @property\n",
    "    def policies(self):\n",
    "        return [agt.actor for agt in self.agents]\n",
    "\n",
    "    @property\n",
    "    def target_policies(self):\n",
    "        return [agt.target_actor for agt in self.agents]\n",
    "\n",
    "    def take_action(self, states, explore):\n",
    "        states = [\n",
    "            torch.tensor([states[i]], dtype=torch.float, device=self.device)\n",
    "            for i in env.agents  # æœªå†™ç¯å¢ƒå¯¼è‡´çš„è­¦å‘Š\n",
    "        ]\n",
    "        \n",
    "        #  æ³¨æ„ï¼šè¿™é‡Œçš„agent.take_actionæ˜¯DDPGç®—æ³•ä¸­çš„\n",
    "        return [\n",
    "            agent.take_action(state, explore)\n",
    "            for agent, state in zip(self.agents, states)\n",
    "        ]\n",
    "\n",
    "    def update(self, sample, i_agent):\n",
    "        obs, act, rew, next_obs, done = sample\n",
    "        cur_agent = self.agents[i_agent]\n",
    "\n",
    "        cur_agent.critic_optimizer.zero_grad()\n",
    "        all_target_act = [\n",
    "            onehot_from_logits(pi(_next_obs))\n",
    "            for pi, _next_obs in zip(self.target_policies, next_obs)\n",
    "        ]\n",
    "        target_critic_input = torch.cat((*next_obs, *all_target_act), dim=1)\n",
    "        target_critic_value = rew[i_agent].view(-1, 1) + self.gamma * cur_agent.target_critic(\n",
    "                target_critic_input) * (1 - done[i_agent].view(-1, 1))\n",
    "        critic_input = torch.cat((*obs, *act), dim=1)\n",
    "        critic_value = cur_agent.critic(critic_input)\n",
    "        critic_loss = self.critic_criterion(critic_value, target_critic_value.detach())\n",
    "        critic_loss.backward()\n",
    "        cur_agent.critic_optimizer.step()\n",
    "\n",
    "        cur_agent.actor_optimizer.zero_grad()\n",
    "        cur_actor_out = cur_agent.actor(obs[i_agent])\n",
    "        cur_act_vf_in = gumbel_softmax(cur_actor_out)\n",
    "        all_actor_acs = []\n",
    "        for i, (pi, _obs) in enumerate(zip(self.policies, obs)):\n",
    "            if i == i_agent:\n",
    "                all_actor_acs.append(cur_act_vf_in)\n",
    "            else:\n",
    "                all_actor_acs.append(onehot_from_logits(pi(_obs)))\n",
    "        vf_in = torch.cat((*obs, *all_actor_acs), dim=1)\n",
    "        actor_loss = -cur_agent.critic(vf_in).mean()\n",
    "        actor_loss += (cur_actor_out**2).mean() * 1e-3\n",
    "        actor_loss.backward()\n",
    "        cur_agent.actor_optimizer.step()\n",
    "\n",
    "    def update_all_targets(self):\n",
    "        for agt in self.agents:\n",
    "            agt.soft_update(agt.actor, agt.target_actor, self.tau)\n",
    "            agt.soft_update(agt.critic, agt.target_critic, self.tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆå§‹åŒ–å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\lib\\site-packages\\pettingzoo\\utils\\conversions.py:158: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.\n",
      "  warnings.warn(\n",
      "e:\\anaconda3\\lib\\site-packages\\pettingzoo\\utils\\conversions.py:144: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 5000\n",
    "episode_length = 25  # æ¯æ¡åºåˆ—çš„æœ€å¤§é•¿åº¦\n",
    "buffer_size = 100000\n",
    "hidden_dim = 64\n",
    "actor_lr = 1e-2\n",
    "critic_lr = 1e-2\n",
    "gamma = 0.95\n",
    "tau = 1e-2\n",
    "batch_size = 1024\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "update_interval = 100\n",
    "minimal_size = 4000\n",
    "\n",
    "observations, infos = env.reset()\n",
    "replay_buffer = rl_utils.ReplayBuffer(buffer_size)\n",
    "\n",
    "state_dims = []\n",
    "action_dims = []\n",
    "\n",
    "action_dims = [i.n for i in env.action_spaces.values()]\n",
    "state_dims = [i.shape[0] for i in env.observation_spaces.values()]\n",
    "\n",
    "critic_input_dim = sum(state_dims) + sum(action_dims)  # æ€»ç»´åº¦43\n",
    "\n",
    "maddpg = MADDPG(env, device, actor_lr, critic_lr, hidden_dim, state_dims,\n",
    "                action_dims, critic_input_dim, gamma, tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¯„ä¼°å’Œè®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(maddpg, n_episode=10, episode_length=25):\n",
    "    # å¯¹å­¦ä¹ çš„ç­–ç•¥è¿›è¡Œè¯„ä¼°,æ­¤æ—¶ä¸ä¼šè¿›è¡Œæ¢ç´¢\n",
    "    env = simple_adversary_v3.parallel_env(render_mode=\"human\")\n",
    "    returns = np.zeros(len(env.agents))\n",
    "    for _ in range(n_episode):\n",
    "        obs, info = env.reset()\n",
    "        for t_i in range(episode_length):\n",
    "            actions = maddpg.take_action(obs, explore=False)\n",
    "            obs, rew, done, truncated, info = env.step(actions)\n",
    "            rew = np.array(rew)\n",
    "            returns += rew / n_episode\n",
    "    return returns.tolist()\n",
    "\n",
    "\n",
    "return_list = []  # è®°å½•æ¯ä¸€è½®çš„å›æŠ¥ï¼ˆreturnï¼‰\n",
    "total_step = 0\n",
    "for i_episode in range(num_episodes):\n",
    "    state, info = env.reset()\n",
    "    # ep_returns = np.zeros(len(env.agents))\n",
    "    for e_i in range(episode_length):\n",
    "        # actionsæ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œæ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ™ºèƒ½ä½“çš„åŠ¨ä½œé›†\n",
    "        actions = maddpg.take_action(state, explore=True)\n",
    "        next_state, reward, done, truncated, _ = env.step(actions)\n",
    "        replay_buffer.add(state, actions, reward, next_state, done, truncated)\n",
    "        state = next_state\n",
    "\n",
    "        total_step += 1\n",
    "        if replay_buffer.size() >= minimal_size and total_step % update_interval == 0:\n",
    "            sample = replay_buffer.sample(batch_size)\n",
    "\n",
    "            # ğŸ‘‡ä¸‹é¢è¿™ä¸ªå‡½æ•°çš„æ“ä½œæ¯”è¾ƒéš¾è§£é‡Šï¼Œæç¤ºï¼šè¾“å…¥ç½‘ç»œçš„ç»´åº¦æ˜¯çŠ¶æ€é•¿åº¦ï¼Œç›¸å½“äºç‰¹å¾ï¼Œå…·ä½“è¿‡ç¨‹çœ‹åé¢\n",
    "            def stack_array(x):\n",
    "                rearranged = [[sub_x[i] for sub_x in x]\n",
    "                              for i in range(len(x[0]))]\n",
    "                return [\n",
    "                    torch.FloatTensor(np.vstack(aa)).to(device)\n",
    "                    for aa in rearranged\n",
    "                ]\n",
    "\n",
    "            sample = [stack_array(x) for x in sample]\n",
    "            for a_i in range(len(env.agents)):\n",
    "                maddpg.update(sample, a_i)\n",
    "            maddpg.update_all_targets()  # è½¯æ›´æ–°æ¥çš„\n",
    "    if (i_episode + 1) % 100 == 0:\n",
    "        ep_returns = evaluate(maddpg, n_episode=100)\n",
    "        return_list.append(ep_returns)\n",
    "        print(f\"Episode: {i_episode+1}, {ep_returns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å…³äºstack_arrayå‡½æ•°çš„è§£é‡Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_array(x):\n",
    "    rearranged = [[sub_x[i] for sub_x in x]\n",
    "                    for i in range(len(x[0]))]\n",
    "    return [\n",
    "        torch.FloatTensor(np.vstack(aa))\n",
    "        for aa in rearranged\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒç»™å‡ºçš„çŠ¶æ€å½¢å¼ï¼Œæ¯è¡Œä»£è¡¨æŸä¸€æ—¶åˆ»ä¸‰ä¸ªæ™ºèƒ½ä½“çš„è§‚æµ‹ï¼Œè¿™é‡Œå‡è®¾æ˜¯éšæœºæŠ½äº†ä¸‰ä¸ªï¼Œå³è¡Œæ•°\n",
    "x = [[np.array([1, 2]), np.array([3, 4]), np.array([3, 5])],\n",
    "     [np.array([4, 2]), np.array([0, 7]), np.array([5, 5])],\n",
    "     [np.array([1, 5]), np.array([4, 7]), np.array([6, 2])],]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([1, 2]), array([4, 2]), array([1, 5])],\n",
       " [array([3, 4]), array([0, 7]), array([4, 7])],\n",
       " [array([3, 5]), array([5, 5]), array([6, 2])]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç¬¬ä¸€æ­¥\n",
    "[[sub_x[i] for sub_x in x] for i in range(len(x[0]))]\n",
    "\n",
    "# å…¶å®å°±æ˜¯è½¬ç½®ï¼Œä½†æ˜¯åˆ—è¡¨ä¸èƒ½è½¬ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [[sub_x[i] for sub_x in x] for i in range(len(x[0]))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2]), array([4, 2]), array([1, 5])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [3],\n",
       "       [5]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 2.],\n",
       "         [4., 2.],\n",
       "         [1., 5.]]),\n",
       " tensor([[3., 4.],\n",
       "         [0., 7.],\n",
       "         [4., 7.]]),\n",
       " tensor([[3., 5.],\n",
       "         [5., 5.],\n",
       "         [6., 2.]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_array(x)  # æŠŠarrayæ‹†äº†ï¼Œå€’æ•°ç¬¬äºŒç»´å˜æˆtorch.tensor\n",
    "# æ­¤æ—¶ç¬¬ä¸€ä¸ªè¾“å…¥çš„æ ·æœ¬ï¼Œå³ç¬¬ä¸€ä¸ªtensorï¼Œå°±æ˜¯è¯¥æ‰¹æ¬¡ä¸­ï¼Œç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“æ‰€ç¢°åˆ°çš„å…¨éƒ¨å½“å‰çŠ¶æ€\n",
    "# ç¬¬äºŒä¸ªtensorï¼Œå°±æ˜¯ç¬¬äºŒä¸ªæ™ºèƒ½ä½“ç¢°åˆ°çš„å…¨éƒ¨å½“å‰çŠ¶æ€\n",
    "# é‡Œé¢tensoréƒ¨åˆ†å°±å’Œå•æ™ºèƒ½ä½“ä¸€æ ·äº†ï¼Œå‚è€ƒåé¢çš„å•æ™ºèƒ½ä½“è¾“å‡ºç»“æœ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å•æ™ºèƒ½ä½“çš„è¾“å‡ºè¿‡ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.9915461 , -0.12975487, -1.7433108 ],\n",
       "        [-0.9959213 ,  0.09022571,  3.2651248 ],\n",
       "        [-0.98676467, -0.1621588 , -1.6151077 ]], dtype=float32),\n",
       " array([[-0.48415332],\n",
       "        [-0.28630628],\n",
       "        [ 0.59497711]]),\n",
       " array([ -9.37310467, -10.37627635,  -9.13395216]),\n",
       " array([[-0.99940634, -0.03445243, -1.91325   ],\n",
       "        [-0.9972526 , -0.07407591,  3.289848  ],\n",
       "        [-0.9967613 , -0.08041708, -1.6474802 ]], dtype=float32),\n",
       " (False, False, False),\n",
       " (False, False, False))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "replay_buffer.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_s, b_a, b_r, b_ns, b_d, b_t = replay_buffer.sample(3)\n",
    "transition_dict = {'states': b_s, 'actions': b_a, 'next_states': b_ns, \n",
    "                    'rewards': b_r, 'dones': b_d, 'truncated': b_t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99729466,  0.07350754,  2.942201  ],\n",
       "       [-0.9995337 , -0.03053527, -2.6963842 ],\n",
       "       [-0.9931456 , -0.1168839 , -8.        ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99729466,  0.07350754,  2.942201  ],\n",
       "       [-0.9995337 , -0.03053527, -2.6963842 ],\n",
       "       [-0.9931456 , -0.1168839 , -8.        ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transition_dict['states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9973,  0.0735,  2.9422],\n",
       "        [-0.9995, -0.0305, -2.6964],\n",
       "        [-0.9931, -0.1169, -8.0000]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.tensor(transition_dict['states'], dtype=torch.float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
